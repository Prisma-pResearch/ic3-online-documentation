"use strict";(self.webpackChunkic_3_online_document=self.webpackChunkic_3_online_document||[]).push([[4395],{4137:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>h});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},p=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=c(a),p=r,h=u["".concat(l,".").concat(p)]||u[p]||m[p]||o;return a?n.createElement(h,i(i({ref:t},d),{},{components:a})):n.createElement(h,i({ref:t},d))}));function h(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:r,i[1]=s;for(var c=2;c<o;c++)i[c]=a[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},7193:(e,t,a)=>{a.d(t,{Z:()=>s});var n=a(7294),r=a(8924);let o;const i=()=>{if(!(0,r.Z)()||!window.document.documentElement)return!1;if(void 0!==o)return o;const e=document.createElement("div");return e.style.display="flex",e.style.flexDirection="column",e.style.rowGap="1px",e.appendChild(document.createElement("div")),e.appendChild(document.createElement("div")),document.body.appendChild(e),o=1===e.scrollHeight,document.body.removeChild(e),o},s=()=>{const[e,t]=n.useState(!1);return n.useEffect((()=>{t(i())}),[]),e}},7838:(e,t,a)=>{a.d(t,{Z:()=>r});var n=a(7294);function r(){const[,e]=n.useReducer((e=>e+1),0);return e}},4443:(e,t,a)=>{a.d(t,{Z:()=>i,c:()=>o});var n=a(7294),r=a(6330);const o=["xxl","xl","lg","md","sm","xs"];function i(){const[,e]=(0,r.dQ)(),t=(e=>({xs:`(max-width: ${e.screenXSMax}px)`,sm:`(min-width: ${e.screenSM}px)`,md:`(min-width: ${e.screenMD}px)`,lg:`(min-width: ${e.screenLG}px)`,xl:`(min-width: ${e.screenXL}px)`,xxl:`(min-width: ${e.screenXXL}px)`}))((e=>{const t=e,a=[].concat(o).reverse();return a.forEach(((e,n)=>{const r=e.toUpperCase(),o=`screen${r}Min`,i=`screen${r}`;if(!(t[o]<=t[i]))throw new Error(`${o}<=${i} fails : !(${t[o]}<=${t[i]})`);if(n<a.length-1){const e=`screen${r}Max`;if(!(t[i]<=t[e]))throw new Error(`${i}<=${e} fails : !(${t[i]}<=${t[e]})`);const o=`screen${a[n+1].toUpperCase()}Min`;if(!(t[e]<=t[o]))throw new Error(`${e}<=${o} fails : !(${t[e]}<=${t[o]})`)}})),e})(e));return n.useMemo((()=>{const e=new Map;let a=-1,n={};return{matchHandlers:{},dispatch:t=>(n=t,e.forEach((e=>e(n))),e.size>=1),subscribe(t){return e.size||this.register(),a+=1,e.set(a,t),t(n),a},unsubscribe(t){e.delete(t),e.size||this.unregister()},unregister(){Object.keys(t).forEach((e=>{const a=t[e],n=this.matchHandlers[a];null==n||n.mql.removeListener(null==n?void 0:n.listener)})),e.clear()},register(){Object.keys(t).forEach((e=>{const a=t[e],r=t=>{let{matches:a}=t;this.dispatch(Object.assign(Object.assign({},n),{[e]:a}))},o=window.matchMedia(a);o.addListener(r),this.matchHandlers[a]={mql:o,listener:r},r(o)}))},responsiveMap:t}}),[e])}},1667:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>de,contentTitle:()=>le,default:()=>pe,frontMatter:()=>se,metadata:()=>ce,toc:()=>ue});var n=a(7462),r=a(7294),o=a(4137),i=a(2920),s=a(7645),l=a(8920),c=a(4184),d=a.n(c),u=a(344),m=a(3124),p=a(7193);function h(e){let{className:t,direction:a,index:n,marginDirection:o,children:i,split:s,wrap:l}=e;const{horizontalSize:c,verticalSize:d,latestIndex:u,supportFlexGap:m}=r.useContext(b);let p={};return m||("vertical"===a?n<u&&(p={marginBottom:c/(s?2:1)}):p=Object.assign(Object.assign({},n<u&&{[o]:c/(s?2:1)}),l&&{paddingBottom:d})),null==i?null:r.createElement(r.Fragment,null,r.createElement("div",{className:t,style:p},i),n<u&&s&&r.createElement("span",{className:`${t}-split`,style:p},s))}var f=a(4173),g=a(1916),v=function(e,t){var a={};for(var n in e)Object.prototype.hasOwnProperty.call(e,n)&&t.indexOf(n)<0&&(a[n]=e[n]);if(null!=e&&"function"==typeof Object.getOwnPropertySymbols){var r=0;for(n=Object.getOwnPropertySymbols(e);r<n.length;r++)t.indexOf(n[r])<0&&Object.prototype.propertyIsEnumerable.call(e,n[r])&&(a[n[r]]=e[n[r]])}return a};const b=r.createContext({latestIndex:0,horizontalSize:0,verticalSize:0,supportFlexGap:!1}),y={small:8,middle:16,large:24};const w=e=>{const{getPrefixCls:t,space:a,direction:n}=r.useContext(m.E_),{size:o=(null==a?void 0:a.size)||"small",align:i,className:s,children:l,direction:c="horizontal",prefixCls:f,split:w,style:k,wrap:x=!1}=e,P=v(e,["size","align","className","children","direction","prefixCls","split","style","wrap"]),O=(0,p.Z)(),[E,T]=r.useMemo((()=>(Array.isArray(o)?o:[o,o]).map((e=>function(e){return"string"==typeof e?y[e]:e||0}(e)))),[o]),M=(0,u.Z)(l,{keepEmpty:!0}),z=void 0===i&&"horizontal"===c?"center":i,j=t("space",f),[I,S]=(0,g.Z)(j),G=d()(j,S,`${j}-${c}`,{[`${j}-rtl`]:"rtl"===n,[`${j}-align-${z}`]:z},s),C=`${j}-item`,N="rtl"===n?"marginLeft":"marginRight";let $=0;const _=M.map(((e,t)=>{null!=e&&($=t);const a=e&&e.key||`${C}-${t}`;return r.createElement(h,{className:C,key:a,direction:c,index:t,marginDirection:N,split:w,wrap:x},e)})),A=r.useMemo((()=>({horizontalSize:E,verticalSize:T,latestIndex:$,supportFlexGap:O})),[E,T,$,O]);if(0===M.length)return null;const L={};return x&&(L.flexWrap="wrap",O||(L.marginBottom=-T)),O&&(L.columnGap=E,L.rowGap=T),I(r.createElement("div",Object.assign({className:G,style:Object.assign(Object.assign({},L),k)},P),r.createElement(b.Provider,{value:A},_)))};w.Compact=f.ZP;const k=w;var x=a(8555),P=a(2550),O=a(7838),E=a(4443);const T=function(){let e=!(arguments.length>0&&void 0!==arguments[0])||arguments[0];const t=(0,r.useRef)({}),a=(0,O.Z)(),n=(0,E.Z)();return(0,r.useEffect)((()=>{const r=n.subscribe((n=>{t.current=n,e&&a()}));return()=>n.unsubscribe(r)}),[]),t.current},M=r.createContext("default"),z=e=>{let{children:t,size:a}=e;const n=r.useContext(M);return r.createElement(M.Provider,{value:a||n},t)},j=M;var I=a(7968),S=a(5503),G=a(4747);const C=e=>{const{antCls:t,componentCls:a,iconCls:n,avatarBg:r,avatarColor:o,avatarSizeBase:i,avatarSizeLG:s,avatarSizeSM:l,avatarFontSizeBase:c,avatarFontSizeLG:d,avatarFontSizeSM:u,borderRadius:m,borderRadiusLG:p,borderRadiusSM:h,lineWidth:f,lineType:g}=e,v=(e,t,r)=>({width:e,height:e,lineHeight:e-2*f+"px",borderRadius:"50%",[`&${a}-square`]:{borderRadius:r},[`${a}-string`]:{position:"absolute",left:{_skip_check_:!0,value:"50%"},transformOrigin:"0 center"},[`&${a}-icon`]:{fontSize:t,[`> ${n}`]:{margin:0}}});return{[a]:Object.assign(Object.assign(Object.assign(Object.assign({},(0,G.Wf)(e)),{position:"relative",display:"inline-block",overflow:"hidden",color:o,whiteSpace:"nowrap",textAlign:"center",verticalAlign:"middle",background:r,border:`${f}px ${g} transparent`,"&-image":{background:"transparent"},[`${t}-image-img`]:{display:"block"}}),v(i,c,m)),{"&-lg":Object.assign({},v(s,d,p)),"&-sm":Object.assign({},v(l,u,h)),"> img":{display:"block",width:"100%",height:"100%",objectFit:"cover"}})}},N=e=>{const{componentCls:t,avatarGroupBorderColor:a,avatarGroupSpace:n}=e;return{[`${t}-group`]:{display:"inline-flex",[`${t}`]:{borderColor:a},"> *:not(:first-child)":{marginInlineStart:n}}}},$=(0,I.Z)("Avatar",(e=>{const{colorTextLightSolid:t,controlHeight:a,controlHeightLG:n,controlHeightSM:r,fontSize:o,fontSizeLG:i,fontSizeXL:s,fontSizeHeading3:l,marginXS:c,colorBorderBg:d,colorTextPlaceholder:u}=e,m=(0,S.TS)(e,{avatarBg:u,avatarColor:t,avatarSizeBase:a,avatarSizeLG:n,avatarSizeSM:r,avatarFontSizeBase:Math.round((i+s)/2),avatarFontSizeLG:l,avatarFontSizeSM:o,avatarGroupSpace:-c,avatarGroupBorderColor:d});return[C(m),N(m)]}));var _=function(e,t){var a={};for(var n in e)Object.prototype.hasOwnProperty.call(e,n)&&t.indexOf(n)<0&&(a[n]=e[n]);if(null!=e&&"function"==typeof Object.getOwnPropertySymbols){var r=0;for(n=Object.getOwnPropertySymbols(e);r<n.length;r++)t.indexOf(n[r])<0&&Object.prototype.propertyIsEnumerable.call(e,n[r])&&(a[n[r]]=e[n[r]])}return a};const A=(e,t)=>{const a=r.useContext(j),[n,o]=r.useState(1),[i,s]=r.useState(!1),[l,c]=r.useState(!0),u=r.useRef(null),p=r.useRef(null),h=(0,P.sQ)(t,u),{getPrefixCls:f}=r.useContext(m.E_),g=()=>{if(!p.current||!u.current)return;const t=p.current.offsetWidth,a=u.current.offsetWidth;if(0!==t&&0!==a){const{gap:n=4}=e;2*n<a&&o(a-2*n<t?(a-2*n)/t:1)}};r.useEffect((()=>{s(!0)}),[]),r.useEffect((()=>{c(!0),o(1)}),[e.src]),r.useEffect((()=>{g()}),[e.gap]);const v=()=>{const{onError:t}=e;!1!==(t?t():void 0)&&c(!1)},{prefixCls:b,shape:y="circle",size:w="default",src:k,srcSet:O,icon:M,className:z,alt:I,draggable:S,children:G,crossOrigin:C}=e,N=_(e,["prefixCls","shape","size","src","srcSet","icon","className","alt","draggable","children","crossOrigin"]),A="default"===w?a:w,L=Object.keys("object"==typeof A&&A||{}).some((e=>["xs","sm","md","lg","xl","xxl"].includes(e))),Z=T(L),H=r.useMemo((()=>{if("object"!=typeof A)return{};const e=E.c.find((e=>Z[e])),t=A[e];return t?{width:t,height:t,lineHeight:`${t}px`,fontSize:M?t/2:18}:{}}),[Z,A]),R=f("avatar",b),[B,D]=$(R),W=d()({[`${R}-lg`]:"large"===A,[`${R}-sm`]:"small"===A}),F=r.isValidElement(k),q=d()(R,W,{[`${R}-${y}`]:!!y,[`${R}-image`]:F||k&&l,[`${R}-icon`]:!!M},z,D),V="number"==typeof A?{width:A,height:A,lineHeight:`${A}px`,fontSize:M?A/2:18}:{};let U;if("string"==typeof k&&l)U=r.createElement("img",{src:k,draggable:S,srcSet:O,onError:v,alt:I,crossOrigin:C});else if(F)U=k;else if(M)U=M;else if(i||1!==n){const e=`scale(${n}) translateX(-50%)`,t={msTransform:e,WebkitTransform:e,transform:e},a="number"==typeof A?{lineHeight:`${A}px`}:{};U=r.createElement(x.Z,{onResize:g},r.createElement("span",{className:`${R}-string`,ref:p,style:Object.assign(Object.assign({},a),t)},G))}else U=r.createElement("span",{className:`${R}-string`,style:{opacity:0},ref:p},G);return delete N.onError,delete N.gap,B(r.createElement("span",Object.assign({},N,{style:Object.assign(Object.assign(Object.assign({},V),H),N.style),className:q,ref:h}),U))};const L=r.forwardRef(A);var Z=a(4627),H=a(6159);const R=e=>{const{getPrefixCls:t,direction:a}=r.useContext(m.E_),{prefixCls:n,className:o="",maxCount:i,maxStyle:s,size:l}=e,c=t("avatar",n),p=`${c}-group`,[h,f]=$(c),g=d()(p,{[`${p}-rtl`]:"rtl"===a},o,f),{children:v,maxPopoverPlacement:b="top",maxPopoverTrigger:y="hover"}=e,w=(0,u.Z)(v).map(((e,t)=>(0,H.Tm)(e,{key:`avatar-key-${t}`}))),k=w.length;if(i&&i<k){const t=w.slice(0,i),a=w.slice(i,k);return t.push(r.createElement(Z.Z,{key:"avatar-popover-key",content:a,trigger:y,placement:b,overlayClassName:`${p}-popover`},r.createElement(L,{style:s},"+"+(k-i)))),h(r.createElement(z,{size:l},r.createElement("div",{className:g,style:e.style},t)))}return h(r.createElement(z,{size:l},r.createElement("div",{className:g,style:e.style},w)))},B=L;B.Group=R;const D=B;var W=a(1413);const F={icon:{tag:"svg",attrs:{viewBox:"64 64 896 896",focusable:"false"},children:[{tag:"path",attrs:{d:"M464 512a48 48 0 1096 0 48 48 0 10-96 0zm200 0a48 48 0 1096 0 48 48 0 10-96 0zm-400 0a48 48 0 1096 0 48 48 0 10-96 0zm661.2-173.6c-22.6-53.7-55-101.9-96.3-143.3a444.35 444.35 0 00-143.3-96.3C630.6 75.7 572.2 64 512 64h-2c-60.6.3-119.3 12.3-174.5 35.9a445.35 445.35 0 00-142 96.5c-40.9 41.3-73 89.3-95.2 142.8-23 55.4-34.6 114.3-34.3 174.9A449.4 449.4 0 00112 714v152a46 46 0 0046 46h152.1A449.4 449.4 0 00510 960h2.1c59.9 0 118-11.6 172.7-34.3a444.48 444.48 0 00142.8-95.2c41.3-40.9 73.8-88.7 96.5-142 23.6-55.2 35.6-113.9 35.9-174.5.3-60.9-11.5-120-34.8-175.6zm-151.1 438C704 845.8 611 884 512 884h-1.7c-60.3-.3-120.2-15.3-173.1-43.5l-8.4-4.5H188V695.2l-4.5-8.4C155.3 633.9 140.3 574 140 513.7c-.4-99.7 37.7-193.3 107.6-263.8 69.8-70.5 163.1-109.5 262.8-109.9h1.7c50 0 98.5 9.7 144.2 28.9 44.6 18.7 84.6 45.6 119 80 34.3 34.3 61.3 74.4 80 119 19.4 46.2 29.1 95.2 28.9 145.8-.6 99.6-39.7 192.9-110.1 262.7z"}}]},name:"message",theme:"outlined"};var q=a(8615),V=function(e,t){return r.createElement(q.Z,(0,W.Z)((0,W.Z)({},e),{},{ref:t,icon:F}))};V.displayName="MessageOutlined";const U=r.forwardRef(V);const X={icon:{tag:"svg",attrs:{viewBox:"64 64 896 896",focusable:"false"},children:[{tag:"path",attrs:{d:"M912 302.3L784 376V224c0-35.3-28.7-64-64-64H128c-35.3 0-64 28.7-64 64v576c0 35.3 28.7 64 64 64h592c35.3 0 64-28.7 64-64V648l128 73.7c21.3 12.3 48-3.1 48-27.6V330c0-24.6-26.7-40-48-27.7zM712 792H136V232h576v560zm176-167l-104-59.8V458.9L888 399v226zM208 360h112c4.4 0 8-3.6 8-8v-48c0-4.4-3.6-8-8-8H208c-4.4 0-8 3.6-8 8v48c0 4.4 3.6 8 8 8z"}}]},name:"video-camera",theme:"outlined"};var Q=function(e,t){return r.createElement(q.Z,(0,W.Z)((0,W.Z)({},e),{},{ref:t,icon:X}))};Q.displayName="VideoCameraOutlined";const J=r.forwardRef(Q);const K={icon:{tag:"svg",attrs:{viewBox:"64 64 896 896",focusable:"false"},children:[{tag:"path",attrs:{d:"M676 565c-50.8 0-92 41.2-92 92s41.2 92 92 92 92-41.2 92-92-41.2-92-92-92zm0 126c-18.8 0-34-15.2-34-34s15.2-34 34-34 34 15.2 34 34-15.2 34-34 34zm204-523H668c0-30.9-25.1-56-56-56h-80c-30.9 0-56 25.1-56 56H264c-17.7 0-32 14.3-32 32v200h-88c-17.7 0-32 14.3-32 32v448c0 17.7 14.3 32 32 32h336c17.7 0 32-14.3 32-32v-16h368c17.7 0 32-14.3 32-32V200c0-17.7-14.3-32-32-32zm-412 64h72v-56h64v56h72v48H468v-48zm-20 616H176V616h272v232zm0-296H176v-88h272v88zm392 240H512V432c0-17.7-14.3-32-32-32H304V240h100v104h336V240h100v552zM704 408v96c0 4.4 3.6 8 8 8h48c4.4 0 8-3.6 8-8v-96c0-4.4-3.6-8-8-8h-48c-4.4 0-8 3.6-8 8zM592 512h48c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8h-48c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8z"}}]},name:"reconciliation",theme:"outlined"};var Y=function(e,t){return r.createElement(q.Z,(0,W.Z)((0,W.Z)({},e),{},{ref:t,icon:K}))};Y.displayName="ReconciliationOutlined";const ee=r.forwardRef(Y),te="features_zddI",ae={Text:{words:"Text",tooltip:"Medical text data",icon:r.createElement(U,null)},Image:{words:"Image",tooltip:"Medical images such as CT Scan",icon:r.createElement(J,null)},EHR:{words:"EHR",tooltip:"Electrical Health Records",icon:r.createElement(ee,null)},NLP:{words:"NLP",tooltip:"Natural Language Processing"}};var ne=[{title:"SOFA",url:"https://i.ytimg.com/vi/fPZrt3WpAAk/maxresdefault.jpg",description:r.createElement(r.Fragment,null,"The online documentation is designed to transfer knowledge between our researchers. You are able to find the details about all projects, datasets and techinical issues in one place."),tagArray:["Text","Image","EHR"],author:"https://github.com/endiliey.png"},{title:"MySurgeryRisk",url:"https://assets.hellahealth.com/wp-content/uploads/sites/2/2022/07/14153656/surgery-risky-746x420.jpg",description:r.createElement(r.Fragment,null,"Please feel free to use the ",r.createElement("strong",null,"search tool")," above to ask your questions. Answers will show up smoothly. If you hope to add more sections, please feel free to add an issue ",r.createElement("a",null,"here"),". swhslwswksqkwsq"),tagArray:["Text","Image"],author:"https://github.com/Chesterguan.png"},{title:"AKI Phenotype",url:"https://media.springernature.com/lw685/springer-static/image/art%3A10.1186%2Fs13054-022-04121-x/MediaObjects/13054_2022_4121_Fig4_HTML.png",description:r.createElement(r.Fragment,null,"The documentation tool is built with ",r.createElement("a",{href:"https://docusaurus.io/"},"Docusaurus")," and maintained by IC3 DevOps. We will keep the documentation updated. swskqskqjwhsqwshkjqjskqwhsjkhqwjk"),tagArray:["Text","NLP"],author:"https://github.com/ruppert20.png"}];function re(e){let{tooltip:t,icon:a,words:n}=e;return r.createElement(i.Z,{title:t},r.createElement(s.ZP,{icon:a},n))}function oe(e){let{url:t,title:a,description:o,tagArray:i,author:s}=e;const{Meta:c}=l.Z;var d=[];for(let n in ae)i.indexOf(n)>-1&&d.push(ae[n]);const u=d.map(((e,t)=>r.createElement(re,(0,n.Z)({key:t},e))));return r.createElement("div",{style:{"margin-right":"auto","margin-top":"1rem",maxWidth:"40%"}},r.createElement(l.Z,{hoverable:!0,cover:r.createElement("img",{style:{margin:"0.1rem"},src:t}),actions:[r.createElement(k,{align:"start"},u)]},r.createElement(c,{title:a,description:o,avatar:r.createElement(D,{src:s})})))}function ie(){return r.createElement("section",{className:te},r.createElement("div",{className:"container"},r.createElement("div",{className:"row"},ne.map(((e,t)=>r.createElement(oe,(0,n.Z)({key:t},e)))))))}const se={},le=void 0,ce={unversionedId:"Models/model_example",id:"Models/model_example",title:"model_example",description:"Model Card InstructGPT",source:"@site/resources/Models/model_example.mdx",sourceDirName:"Models",slug:"/Models/model_example",permalink:"/ic3-online-documentation/resources/Models/model_example",draft:!1,tags:[],version:"current",lastUpdatedBy:"srisharanya Injarapu",lastUpdatedAt:1738621240,formattedLastUpdatedAt:"Feb 3, 2025",frontMatter:{},sidebar:"mySidebar",previous:{title:"Resources",permalink:"/ic3-online-documentation/resources/intro"},next:{title:"OMOP CDM",permalink:"/ic3-online-documentation/resources/OMOP/Introduction"}},de={},ue=[{value:"Model Details",id:"model-details",level:2},{value:"Model date",id:"model-date",level:3},{value:"Model type",id:"model-type",level:3},{value:"Paper &amp; samples",id:"paper--samples",level:3},{value:"Model version",id:"model-version",level:3},{value:"Model Use",id:"model-use",level:2},{value:"Data and Performance",id:"data-and-performance",level:2},{value:"Data",id:"data",level:3},{value:"Performance",id:"performance",level:3},{value:"Limitations",id:"limitations",level:2},{value:"Model limitations",id:"model-limitations",level:3},{value:"Methodology limitations",id:"methodology-limitations",level:3}],me={toc:ue};function pe(e){let{components:t,...a}=e;return(0,o.kt)("wrapper",(0,n.Z)({},me,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)(ie,{mdxType:"ModelCards"}),(0,o.kt)("br",null),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Model Card InstructGPT"),(0,o.kt)("h1",{id:"instructgpt-model-card"},"InstructGPT Model Card"),(0,o.kt)("p",null,"Last updated: January 2022"),(0,o.kt)("p",null,"Based on ",(0,o.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/1810.03993"},"Model Cards for Model Reporting (Mitchell et al.)"),", we\u2019re providing some accompanying information about InstructGPT."),(0,o.kt)("h2",{id:"model-details"},"Model Details"),(0,o.kt)("p",null,"InstructGPT is a GPT-style language model. Researchers at OpenAI developed the model by fine-tuning GPT-3 to follow instructions using human feedback. There are three model sizes: 1.3B, 6B, and 175B parameters."),(0,o.kt)("h3",{id:"model-date"},"Model date"),(0,o.kt)("p",null,"January 2022"),(0,o.kt)("h3",{id:"model-type"},"Model type"),(0,o.kt)("p",null,"Language model"),(0,o.kt)("h3",{id:"paper--samples"},"Paper & samples"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf"},"Training language models to follow instructions with human feedback")),(0,o.kt)("p",null,"We release samples from our models on public NLP datasets that require sampling ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/openai/following-instructions-human-feedback/tree/main/automatic-eval-samples"},"here"),"."),(0,o.kt)("h3",{id:"model-version"},"Model version"),(0,o.kt)("p",null,"InstructGPT is described in the ",(0,o.kt)("a",{parentName:"p",href:"https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf"},"above paper"),"."),(0,o.kt)("p",null,"The versions deployed on the OpenAI API are fine-tuned using the same human feedback data, using a slightly different procedure, which will be detailed in a forthcoming publication."),(0,o.kt)("h2",{id:"model-use"},"Model Use"),(0,o.kt)("p",null,"The intended direct users of InstructGPT are developers who access its capabilities via the OpenAI API. Through the OpenAI API, the model can be used by those who may not have AI development experience, to build and explore language modeling systems across a wide range of functions. We also anticipate that the model will continue to be used by researchers to better understand the behaviors, capabilities, biases, and constraints of large-scale language models."),(0,o.kt)("p",null,"Due to InstructGPT\u2019s limitations (described below), and the breadth and open-ended nature of its capabilities, access and use are subject to OpenAI\u2019s API Usage Guidelines, and API Terms of Use, which are designed to prohibit the use of the API in a way that causes societal harm. We review all use cases before customers deploy API models in production, and have systems in place to revoke access if necessary after moving to production. Additionally, we provide guidance to users on some of the potential safety risks they should consider - and related mitigations."),(0,o.kt)("h2",{id:"data-and-performance"},"Data and Performance"),(0,o.kt)("h3",{id:"data"},"Data"),(0,o.kt)("p",null,"InstructGPT models are initialized from GPT-3 models, whose training dataset is composed of text posted to the internet or uploaded to the internet (e.g., books). The internet data that the GPT-3 models were trained on and evaluated against includes:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"a version of the ",(0,o.kt)("a",{parentName:"li",href:"https://commoncrawl.org/the-data/"},"CommonCrawl dataset")," filtered based on similarity to high-quality reference corpora,"),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"},"an expanded version of the Webtext dataset"),","),(0,o.kt)("li",{parentName:"ol"},"two internet-based book corpora, and"),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/Main_Page"},"English-language Wikipedia"),".")),(0,o.kt)("p",null,"InstructGPT is then further fine-tuned on a dataset labeled by human labelers. The labelers comprise a team of about 40 contractors whom we hired through Upwork and ScaleAI. Our aim was to select a group of labelers who were sensitive to the preferences of different demographic groups, and who were good at identifying outputs that were potentially harmful. Thus, we conducted a screening test designed to measure labeler performance on these axes. We selected labelers who performed well on this test. We collaborated closely with the labelers over the course of the project. We had an onboarding process to train labelers on the project, wrote detailed instructions for each task, and answered labeler questions in a shared chat room."),(0,o.kt)("p",null,"The dataset consists of input prompts (from the OpenAI API or written by labelers), demonstrations of the desired model behavior written by our labelers, and labeler rankings of outputs from multiple models. The text prompts submitted to the OpenAI API were from an earlier version of the InstructGPT models (trained via supervised learning on a subset of our demonstration data on the Playground interface). Customers using the Playground were informed that their data could be used to train further models via a recurring notification any time InstructGPT models were used. To reduce the risk of the models learning potentially sensitive customer details, we filtered all prompts in the training split for personally identifiable information (PII). Some of our prompts were also written by contractors themselves, because we needed an initial source of instruction-like prompts to bootstrap the process, and these kinds of prompts weren't often submitted to the regular GPT-3 models on the API."),(0,o.kt)("h3",{id:"performance"},"Performance"),(0,o.kt)("p",null,"We measure InstructGPT\u2019s performance on two categories of tasks: prompts submitted to the OpenAI API, and public academic datasets. Results on each can be found in the ",(0,o.kt)("a",{parentName:"p",href:"https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf"},"paper"),". Overall, InstructGPT outputs are significantly preferred by labelers over outputs from GPT-3 on our API distribution. In our paper, we show that InstructGPT produces fewer toxic outputs than GPT-3 on the RealToxicityPrompts dataset, generates more truthful and informative answers on the TruthfulQA dataset, and shows improvements in appropriateness, obeying explicit constraints in the instruction, attempting the correct instruction, and not making up information on \u201cclosed-domain\u201d tasks. However, this does not mean that the model is fully aligned or fully safe, as we detail in the next section."),(0,o.kt)("h2",{id:"limitations"},"Limitations"),(0,o.kt)("h3",{id:"model-limitations"},"Model limitations"),(0,o.kt)("p",null,"InstructGPT and our analysis of it have a number of limitations. Some of them are inherent to any model with machine learning (ML) components that can have high-bandwidth, open-ended interactions with people (e.g. via natural language): ML components have limited robustness; ML components are biased; open-ended systems have large surface areas for risk; and safety is a moving target for ML systems. Like any model with ML components, InstructGPT can only be expected to provide reasonable outputs for inputs similar to those in its training data."),(0,o.kt)("p",null,"We outline some further limitations below. These limitations are similar to those of the original GPT-3 model, though many of them may be mitigated by our InstructGPT training procedure."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Repetition: GPT-3 samples sometimes repeat themselves semantically at the document level, and can lose coherence over long passages, contradict themselves, and occasionally contain non-sequitur sentences or paragraphs.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Lack of real-world grounding: GPT-3, like other large pretrained language models, is not grounded in other modalities of experience, such as video, real-world physical interaction, or human feedback, and thus lacks a large amount of context about the world.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Predominantly English: GPT-3 is trained largely on text in the English language, and is best suited for classifying, searching, summarizing, or generating such text. GPT-3 will by default perform worse on inputs that are different from the data distribution it is trained on, including non-English languages as well as specific dialects of English that are not as well-represented in  training data.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Interpretability and predictability: the capacity to interpret or predict how GPT-3 will behave is very limited, a limitation common to most deep learning systems, especially in models of this scale.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"High variance on novel inputs: GPT-3 is not necessarily well-calibrated in its predictions on novel inputs. This can be observed in the much higher variance in its performance as compared to that of humans on standard benchmarks.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Biases: GPT-3, like all large language models trained on internet corpora, will generate stereotyped or prejudiced content. The model has the propensity to retain and magnify biases it inherited from any part of its training, from the datasets we selected to the training techniques we chose. This is concerning, since model bias could harm people in the relevant groups in different ways by entrenching existing stereotypes and producing demeaning portrayals amongst other potential harms.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Follow harmful instructions: Perhaps the greatest limitation of InstructGPT relative to GPT-3 is that, in most cases, they follow the user's instruction, even if that could lead to harm in the real world.  For example, when given a prompt instructing the models to be maximally biased, InstructGPT generates more toxic outputs than equivalently-sized GPT-3 models. We discuss potential mitigations in the following sections."))),(0,o.kt)("h3",{id:"methodology-limitations"},"Methodology limitations"),(0,o.kt)("p",null,"The behavior of our InstructGPT models is determined in part by the human feedback obtained from our contractors. Some of the labeling tasks rely on value judgments that may be impacted by the identity of our contractors, their beliefs, cultural backgrounds, and personal history. We hired about 40 contractors, guided by their performance on a screening test meant to judge how well they could identify and respond to sensitive prompts, and their agreement rate with researchers on a labeling task with detailed instructions. We kept our team of contractors small because it's easier to have high-bandwidth communication with a smaller set of contractors who are doing the task full-time. However, this group is clearly not representative of the full spectrum of people who will use and be affected by our deployed models. As a simple example, our labelers are primarily English-speaking and our data consists almost entirely of English instructions.")))}pe.isMDXComponent=!0}}]);